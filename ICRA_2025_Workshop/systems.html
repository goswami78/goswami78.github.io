<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="table.css" type="text/css" />
<img src="burnIR.png" alt="Drone monitoring a forest burn" width="1920px" height="232px" />
<title>Systems and Missions</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="program.html">Program</a></div>
<div class="menu-item"><a href="lightning.html">Call&nbsp;for&nbsp;contributions</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Systems and Missions</h1>
</div>
<h2>Zhaodan Kong</h2>
<h3>Uncrewed Aerial System for Early Wildfire Detection </h3>
<h3>Abstract</h3>
<p>Due to the joint factors of an expanding wildland-urban interface (WUI) and climate change, we are witnessing an increasing number of wildfires that burn bigger, with a higher intensity, and spread out of control faster. Damages caused by wildfires, in terms of the total area burned, the firefighting cost, and the lives lost (directly by wildfire or indirectly by resulting air population), have doubled over the past two decades. Early wildfire detection enhances our capability to respond swiftly and effectively to emerging fire threats, enabling targeted efforts and implementation of evacuation protocols to mitigate the impact on lives, property, and natural ecosystems. In this talk, I will present our recent results on developing and testing an uncrewed aerial system (UAS) for early wildfire detection. Specifically, I will describe an uncrewed aerial vehicle (UAV) uniquely designed for wildfire detection and monitoring. In addition, I will present how the UAV was used to collect data near prescribed burns conducted by the California Department of Forestry and Fire Protection (CAL FIRE) and how the data was used to develop a data-driven plume dynamics model. Finally, results will be presented on how the model and a source allocation algorithm were used to track fire plumes by the UAV in real time. 
</p>
<h3>Bio</h3>
<table class="imgtable"><tr><td>
<img src="photos/kong.jpg" alt="alt text" width="200px" height="300px" />&nbsp;</td>
<td align="left"><p>Dr. Zhaodan Kong is an Associate Professor in the Department of Mechanical and Aerospace Engineering at the University of California, Davis. He earned his B.S. and M.S. degrees in Astronautics and Mechanics from Harbin Institute of Technology in 2004 and 2006, and completed his Ph.D. in Aerospace Engineering with a minor in Cognitive Science at the University of Minnesota in 2012. He then worked as a Postdoctoral Associate at Boston University before joining UC Davis in 2015. Dr. Kong’s research focuses on control theory, machine learning, and formal methods, with applications in autonomous systems, human-autonomy teaming, cyber-physical systems, and neural engineering. He directs the Cyber-Human-Physical Systems Lab and is affiliated with several interdisciplinary centers at UC Davis, including the Center for Spaceflight Research and the Center for Neuroengineering &amp; Medicine. He is a Senior Member of AIAA and IEEE, and a member of ACM and the Vertical Flight Society.
</p>
</td></tr></table>
<h2>Sheng Cheng</h2>
<h3>Navigating Complex Spatiotemporal Processes: Mobile Robots for Monitoring and Controlling Wildland Fire </h3>
<h3>Abstract</h3>
<p>In this talk, I will present a cooperative framework designed for the estimation and control of complex spatiotemporal fields, with specific relevance to wildland fire management. Monitoring and controlling dynamic, large-scale environmental processes, such as fire spread, poses significant challenges for human operators. By delegating these tasks to autonomous mobile robots, we can enhance both the efficiency and safety of fire management operations. The core of the framework models the spatiotemporal field as a partial differential equation (PDE). Mobile robots equipped with sensors and actuators estimate and influence this evolving process, which requires dynamic control strategies. I will discuss the nonlinear optimization approach that simultaneously seeks optimal robot actuation and guidance while accounting for real-world limitations, such as onboard resources and constrained mobility. Additionally, I will present results from hardware-in-the-loop simulations with multi-robot systems, which demonstrate the framework's robustness in outdoor environments. These insights into cooperative robotic systems offer practical solutions for handling dynamic field processes, such as wildland fires, through autonomous estimation and control. The talk will also explore potential adaptations of this framework to fire-resilient ecosystems and climate management. 
</p>
<h3>Bio</h3>
<table class="imgtable"><tr><td>
<img src="photos/cheng.jpg" alt="alt text" width="200px" height="300px" />&nbsp;</td>
<td align="left"><p>Sheng Cheng is a Postdoctoral Research Associate at the University of Illinois Urbana-Champaign (UIUC), working under the guidance of Dr. Naira Hovakimyan. He leads the ACRL Multirotor Team, focusing on adaptive control, robotics, and optimization. Sheng earned his Ph.D. in Electrical Engineering from the University of Maryland in 2021, where he was advised by Dr. Derek A. Paley. His doctoral research centered on the optimal guidance and control of distributed parameter systems using mobile actuators and sensors. He also holds a B.Eng. in Control Science and Engineering from Harbin Institute of Technology, China. In 2025, Sheng was recognized as a Future Leader in Robotics and AI by the University of Maryland. His notable publications include work on DiffTune, an auto-tuning framework through auto-differentiation, and L1Quad, an adaptive augmentation of geometric control for agile quadrotors.
</p>
</td></tr></table>
<h2>Adyasha D. Mohanty</h2>
<h3>Lightning Talk: Wildfire Detection and Visualization using ML-Aided Tools and Sensor Fusion</h3>
<h3>Bio</h3>
<table class="imgtable"><tr><td>
<img src="photos/Mohanty.jpg" alt="alt text" width="200px" height="296px" />&nbsp;</td>
<td align="left"><p>Dr. Adyasha Mohanty is an Assistant Professor of Robotics and Engineering at Harvey Mudd College, where she leads a research group focused on developing algorithms at the intersection of traditional and machine learning methods for autonomous vehicles. She earned her B.S. in Aerospace Engineering from Georgia Tech in 2019, and her M.S. and Ph.D. in Aerospace Engineering from Stanford University in 2024.
Dr. Mohanty has served as a peer reviewer for over 50 conference and journal articles, as a Session Chair for ION ITM and IEEE PLANS conference and earned the ION Outstanding Peer Reviewer Award for 2024. She is a member of the AIAA GNC National Technical Committee and contributes actively to outreach in STEM through various programs, including REUs, AI4ALL, and community college partnerships.
</p>
</td></tr></table>
</td>
</tr>
</table>
</body>
</html>
